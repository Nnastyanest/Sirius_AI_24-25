{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 0. Установка и Импорт"
      ],
      "metadata": {
        "id": "xX6cuwUg4QJk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain\n",
        "!pip install -U langchain-community\n",
        "!pip install gigachat\n",
        "!pip install --upgrade --quiet  langchain-google-genai pillow\n",
        "!pip install --upgrade --quiet  yandexcloud\n",
        "!pip install yandex-chain\n",
        "!pip install -qU langchain-openai"
      ],
      "metadata": {
        "id": "HiDN6u3p4P49"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pydantic>=1.10.0"
      ],
      "metadata": {
        "id": "YN7uN6dJ521O"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Настраиваем Api ключи\n",
        "credentials_gigachat = \"...\"\n",
        "GOOGLE_API_KEY = '...'\n",
        "OPENAI_API_KEY = '...'\n",
        "secret_yandexgpt2 = '...'\n",
        "folder_id_yandex = \"...\"\n",
        "\n",
        "import getpass\n",
        "import os\n",
        "if \"GOOGLE_API_KEY\" not in os.environ:\n",
        "    os.environ[\"GOOGLE_API_KEY\"] = GOOGLE_API_KEY"
      ],
      "metadata": {
        "id": "VPmtOn4t4fpC"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chat_models.gigachat import GigaChat\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from yandex_chain import ChatYandexGPT\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.messages import HumanMessage, SystemMessage\n",
        "import re"
      ],
      "metadata": {
        "id": "6Vid3NgUB3Iw"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Объявляем класс работы с моделями"
      ],
      "metadata": {
        "id": "D2wqY2yq4tvy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Model:\n",
        "    def __init__(self, model_name):\n",
        "        match model_name:\n",
        "            case \"gpt-4o\":\n",
        "                self.model = ChatOpenAI(\n",
        "                    model_name=\"gpt-4o\",\n",
        "                    openai_api_key=OPENAI_API_KEY\n",
        "                )\n",
        "            case 'gigachat':\n",
        "                self.model = GigaChat(\n",
        "                    credentials=credentials_gigachat,\n",
        "                    model='GigaChat',\n",
        "                    verify_ssl_certs=False\n",
        "                )\n",
        "            case 'gemeni':\n",
        "                self.model = ChatGoogleGenerativeAI(\n",
        "                    model=\"gemini-pro\",\n",
        "                    convert_system_message_to_human=True\n",
        "                )\n",
        "            case 'yandexGPT':\n",
        "                self.model = ChatYandexGPT(\n",
        "                    folder_id=folder_id_yandex,\n",
        "                    api_key=secret_yandexgpt2\n",
        "                )\n",
        "\n",
        "    def get_predict(self, system_prompt, human_prompt):\n",
        "        message = [\n",
        "            SystemMessage(content=system_prompt),\n",
        "            HumanMessage(content=human_prompt),\n",
        "        ]\n",
        "        return self.model(message).content\n",
        "\n",
        "def split_text(text, chunk_size=400):\n",
        "    \"\"\"Разделение текста на части с ограничением по количеству слов.\"\"\"\n",
        "    words = text.split()\n",
        "    chunks = []\n",
        "\n",
        "    for i in range(0, len(words), chunk_size):\n",
        "        chunk = \" \".join(words[i:i + chunk_size])\n",
        "        chunks.append(chunk)\n",
        "\n",
        "    return chunks\n",
        "\n",
        "\n",
        "def summarize_block(model, text_block):\n",
        "    \"\"\"Создание конспекта блока в формате LaTeX\"\"\"\n",
        "    prompt =  \"Преобразуй следующий текст лекции в краткий конспект на русском языке с использованием LaTeX. Используй основные принципы оформления: выделяй важные термины с помощью жирного (\\textbf{}) или курсива (\\textit{}), добавляй заголовки с командами \\section{}, \\subsection{}, а также, если нужно, используй списки (\\begin{itemize} или \\begin{enumerate}). Сохрани чёткость и структурированность текста.\"\n",
        "    summary = model.get_predict(prompt, text_block)\n",
        "    return summary\n",
        "\n",
        "def generate_latex_document(text, model_name):\n",
        "    \"\"\"Генерация полного LaTeX-документа\"\"\"\n",
        "    model = Model(model_name)\n",
        "    blocks = split_text(text)\n",
        "    latex_sections = []\n",
        "\n",
        "    for i, block in enumerate(blocks):\n",
        "        summary = summarize_block(model, block)\n",
        "        latex_sections.append(summary)\n",
        "\n",
        "    latex_document = \"\\\\documentclass{article}\\n\\\\usepackage[english, russian]{babel}\\n\\\\begin{document}\\n\" + \"\\n\".join(latex_sections) + \"\\n\\\\end{document}\"\n",
        "    convert_latex = convert_bold_to_latex(latex_document)\n",
        "    return convert_latex\n",
        "\n",
        "def convert_bold_to_latex(text):\n",
        "    \"\"\"Заменяет выделение жирным с **текст** на \\\\textbf{текст} для LaTeX.\"\"\"\n",
        "    return re.sub(r\"\\*\\*(.*?)\\*\\*\", r\"\\\\textbf{\\1}\", text)"
      ],
      "metadata": {
        "id": "KuANNKbJ41s_"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Тестируем!"
      ],
      "metadata": {
        "id": "0_KV4tBa42U6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Model(\"gemeni\")\n",
        "model.get_predict(\"Напиши привет\", 'Привет!')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "NJWTrl_W6Hro",
        "outputId": "d2073d5e-91b5-4e11-a9fc-f8be5edfd90b"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_google_genai/chat_models.py:362: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Привет!'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "O_MQXCZNt0_e"
      },
      "outputs": [],
      "source": [
        "with open(\"/content/лекция.txt\", 'r') as f:\n",
        "    text_to_notes = f.read().strip()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"gemeni\"\n",
        "latex_output = generate_latex_document(text_to_notes, model_name)\n",
        "\n",
        "with open(\"lecture_summary.tex\", \"w\") as file:\n",
        "    file.write(convert_bold_to_latex(latex_output))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D1rTEk5j6vU6",
        "outputId": "30dc385f-adce-486f-b013-aca3f97a8982"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_google_genai/chat_models.py:362: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n",
            "/usr/local/lib/python3.10/dist-packages/langchain_google_genai/chat_models.py:362: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n",
            "/usr/local/lib/python3.10/dist-packages/langchain_google_genai/chat_models.py:362: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n",
            "/usr/local/lib/python3.10/dist-packages/langchain_google_genai/chat_models.py:362: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n",
            "/usr/local/lib/python3.10/dist-packages/langchain_google_genai/chat_models.py:362: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n",
            "/usr/local/lib/python3.10/dist-packages/langchain_google_genai/chat_models.py:362: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n",
            "/usr/local/lib/python3.10/dist-packages/langchain_google_genai/chat_models.py:362: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n",
            "/usr/local/lib/python3.10/dist-packages/langchain_google_genai/chat_models.py:362: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n",
            "/usr/local/lib/python3.10/dist-packages/langchain_google_genai/chat_models.py:362: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n",
            "/usr/local/lib/python3.10/dist-packages/langchain_google_genai/chat_models.py:362: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n",
            "/usr/local/lib/python3.10/dist-packages/langchain_google_genai/chat_models.py:362: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n",
            "/usr/local/lib/python3.10/dist-packages/langchain_google_genai/chat_models.py:362: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n",
            "/usr/local/lib/python3.10/dist-packages/langchain_google_genai/chat_models.py:362: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n",
            "/usr/local/lib/python3.10/dist-packages/langchain_google_genai/chat_models.py:362: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n",
            "/usr/local/lib/python3.10/dist-packages/langchain_google_genai/chat_models.py:362: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n",
            "/usr/local/lib/python3.10/dist-packages/langchain_google_genai/chat_models.py:362: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n",
            "/usr/local/lib/python3.10/dist-packages/langchain_google_genai/chat_models.py:362: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n",
            "/usr/local/lib/python3.10/dist-packages/langchain_google_genai/chat_models.py:362: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uSIjHcyIEH5U"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}